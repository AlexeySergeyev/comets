{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "\n",
    "from astroquery.jplhorizons import Horizons\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy.time import Time\n",
    "from astropy.config import set_temp_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init = pd.read_csv('data/comets_list2.csv')\n",
    "df_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ztf_name_to_irsa_url(name: str,\n",
    "                         base: str = \"https://irsa.ipac.caltech.edu/ibe/data/ztf/products\",\n",
    "                         product: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Convert a ZTF filename to its IRSA IBE URL.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        e.g. 'ztf_20180508456111_000386_zr_c08_o_q2_sciimg.fits'\n",
    "    base : str\n",
    "        Base IRSA IBE URL (rarely needs changing).\n",
    "    product : str | None\n",
    "        ZTF product subtree. If None, try to infer ('sci', 'raw', 'cal') from the name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Full URL to the file on IRSA.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError if the name doesnâ€™t match the expected ZTF pattern.\n",
    "    \"\"\"\n",
    "    # Try to infer product subtree if not provided\n",
    "    if product is None:\n",
    "        lowered = name.lower()\n",
    "        if \"sci\" in lowered:\n",
    "            product = \"sci\"\n",
    "        elif \"raw\" in lowered:\n",
    "            product = \"raw\"\n",
    "        elif \"cal\" in lowered:\n",
    "            product = \"cal\"\n",
    "        else:\n",
    "            product = \"sci\"  # sensible default\n",
    "\n",
    "    # Parse ztf_{YYYY}{MM}{DD}{FIELD6}_{...}.fits\n",
    "    m = re.match(r\"^ztf_(\\d{4})(\\d{4})(\\d{6})_\", name, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        raise ValueError(\"Filename doesn't look like a ZTF name: expected 'ztf_YYYYMMDDFFFFFF_...'.\")\n",
    "    year, mmdd, field6 = m.groups()\n",
    "\n",
    "    return f\"{base}/{product}/{year}/{mmdd}/{field6}/{name}.fits\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ztf_colors = {\n",
    "    'ZTF_g': 'Greens_r',\n",
    "    'ZTF_r': 'Reds_r',\n",
    "    'ZTF_i': 'Oranges_r'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust ephemeris fetch: Horizons with retries + local CSV fallback\n",
    "from time import sleep\n",
    "from functools import lru_cache\n",
    "import warnings\n",
    "\n",
    "@lru_cache(maxsize=4096)\n",
    "def _horizons_ephem_cached(name: str, mjd: float, location: str = 'I41'):\n",
    "    obj = Horizons(id=name, location=location, epochs=float(mjd))\n",
    "    eph = obj.ephemerides()\n",
    "    ra = float(eph['RA'][0])\n",
    "    dec = float(eph['DEC'][0])\n",
    "    tmag = float(eph['Tmag'][0]) if 'Tmag' in eph.colnames else float('nan')\n",
    "    return ra, dec, tmag\n",
    "\n",
    "\n",
    "def get_comet_position(name: str, mjd: float, location: str = 'I41', retries: int = 4, backoff_s: float = 3.0):\n",
    "    \"\"\"\n",
    "    Try to get (RA, Dec, Tmag) at given MJD from JPL Horizons with exponential backoff.\n",
    "    On failure, fall back to local CSV in data/jpl2/<name>_jplhorizons.csv using nearest JD.\n",
    "    Returns a dict: {ra, dec, tmag, source}\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for i in range(max(retries, 0)):\n",
    "        try:\n",
    "            ra, dec, tmag = _horizons_ephem_cached(name, float(mjd), location)\n",
    "            return {'ra': ra, 'dec': dec, 'tmag': tmag, 'source': 'horizons'}\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            if i < retries - 1:\n",
    "                sleep(backoff_s * (2 ** i))\n",
    "\n",
    "    # Fallback to local CSV (precomputed Horizons table)\n",
    "    csv_path = f\"data/jpl2/{name.replace('/', '_')}_jplhorizons.csv\"\n",
    "    if os.path.exists(csv_path):\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            # Expect columns: 'datetime_jd', 'RA', 'DEC', 'Tmag' (as seen in repo files)\n",
    "            if 'datetime_jd' in df.columns and 'RA' in df.columns and 'DEC' in df.columns:\n",
    "                jd_target = float(mjd) + 2400000.5\n",
    "                idx = (df['datetime_jd'] - jd_target).abs().idxmin()\n",
    "                ra = float(df.loc[idx, 'RA'])\n",
    "                dec = float(df.loc[idx, 'DEC'])\n",
    "                tmag = float(df.loc[idx, 'Tmag']) if 'Tmag' in df.columns and pd.notna(df.loc[idx, 'Tmag']) else float('nan')\n",
    "                return {'ra': ra, 'dec': dec, 'tmag': tmag, 'source': 'local-jpl2'}\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "\n",
    "    raise RuntimeError(f\"Ephemeris unavailable for {name} at MJD={mjd}: {last_err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_init.iterrows():\n",
    "    visible_filename = f\"data/visible2/{row['Comet'].replace('/', '_').replace(' ', '')}_visible.csv\"\n",
    "    df_cadc = pd.read_csv(visible_filename)\n",
    "    comet_name = row['Comet']\n",
    "    print(f\"Processing {comet_name} from {visible_filename}\")\n",
    "\n",
    "    # get observations from the ZTF\n",
    "    df_ztf = df_cadc[df_cadc['Telescope/Instrument'] == 'ZTF']\n",
    "    print(f\"File: {visible_filename}, entries: {len(df_ztf)}\")\n",
    "    if len(df_ztf) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Ensure output folders exist\n",
    "    os.makedirs('data/comets/cutouts/ztf', exist_ok=True)\n",
    "    os.makedirs('data/comets/figs/ztf', exist_ok=True)\n",
    "\n",
    "    for index, row in df_ztf.iterrows():\n",
    "        print(f\"Row index: {index}, MJD: {row['MJD']}\")\n",
    "        url = ztf_name_to_irsa_url(row['Image'])\n",
    "\n",
    "        print(f\"Downloading from URL: {url}\")\n",
    "        with set_temp_cache(path='./data/comets/fits/ztf/', delete=False):\n",
    "            hdul = fits.open(url, cache=True, memmap=True)\n",
    "\n",
    "        try:\n",
    "            # Get WCS and observation time\n",
    "            w = WCS(hdul[0].header)\n",
    "            obs_time = Time(hdul[0].header.get('OBSMJD', 'Unknown'), format='mjd')\n",
    "            \n",
    "            # Get filter band\n",
    "            filter_band = hdul[0].header.get('FILTER', 'Unknown').strip()\n",
    "            \n",
    "            # Get exposure time\n",
    "            exposure = hdul[0].header.get('EXPTIME', 'Unknown')\n",
    "            \n",
    "            # Checking if the file already processed\n",
    "            out_filename = f\"data/comets/cutouts/ztf/{comet_name.replace('/', '_')}_ztf_{obs_time.iso}.fits\"\n",
    "            if os.path.exists(out_filename):\n",
    "                print(\"File already processed\")\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # Get comet position at observation time with retries and fallback\n",
    "            print(f\"Computing the comet position at MJD={obs_time.mjd}\")\n",
    "            try:\n",
    "                ephem = get_comet_position(comet_name, obs_time.mjd, location='I41', retries=4, backoff_s=3.0)\n",
    "            except Exception as e:\n",
    "                print(f\"Ephemeris fetch failed: {e}. Skipping this frame.\")\n",
    "                continue\n",
    "\n",
    "            ra_comet = ephem['ra']\n",
    "            dec_comet = ephem['dec']\n",
    "            tmag = ephem.get('tmag', float('nan'))\n",
    "            print(f\"Comet position at observation time: RA={ra_comet}, Dec={dec_comet} (source={ephem['source']})\")\n",
    "            print(f\"Filter: {filter_band}, Exposure: {exposure} sec\")\n",
    "            if pd.notna(tmag):\n",
    "                print(f\"Predicted comet magnitude: {tmag}\")\n",
    "            \n",
    "            # Create SkyCoord for the comet position\n",
    "            coord = SkyCoord(ra_comet*u.deg, dec_comet*u.deg, frame='icrs')\n",
    "\n",
    "            # Check if the position is within the image FOV\n",
    "            hdu = hdul[0]\n",
    "            ny, nx = hdu.data.shape\n",
    "            x_pix, y_pix = w.world_to_pixel(coord)\n",
    "            in_fov = (0 <= x_pix < nx) and (0 <= y_pix < ny)\n",
    "            \n",
    "            if in_fov:\n",
    "                size = u.Quantity((1, 1), u.arcmin)\n",
    "                cutout = Cutout2D(hdu.data, (x_pix, y_pix), size, wcs=w)\n",
    "                \n",
    "                # Save cutout to a new FITS file\n",
    "                hdu_out = fits.PrimaryHDU(data=cutout.data, header=cutout.wcs.to_header())\n",
    "                hdu_out.header['COMET'] = comet_name\n",
    "                hdu_out.header['OBSMJD'] = obs_time.mjd\n",
    "                hdu_out.header['FILTER'] = filter_band\n",
    "                hdu_out.header['ORIGFILE'] = os.path.basename(url)\n",
    "                hdu_out.header['RA_COM'] = ra_comet\n",
    "                hdu_out.header['DEC_COM'] = dec_comet\n",
    "                hdu_out.header['CUTSIZE'] = '1 arcmin'\n",
    "                hdu_out.header['EXPTIME'] = exposure\n",
    "                \n",
    "                out_filename = f\"data/comets/cutouts/ztf/{comet_name.replace('/', '_')}_ztf_{obs_time.iso}.fits\"\n",
    "                hdu_out.writeto(out_filename, overwrite=True)\n",
    "                print(f'Wrote cutout to {out_filename}')\n",
    "\n",
    "                # Plot the cutout with the comet position\n",
    "                fig = plt.figure(figsize=(5, 5))\n",
    "                ax = fig.add_subplot(1, 1, 1, projection=cutout.wcs)\n",
    "                norm = simple_norm(cutout.data, 'sqrt', percent=95.0)\n",
    "                cmap = ztf_colors.get(filter_band, 'gray')\n",
    "                ax.imshow(cutout.data, origin='lower', cmap=cmap, norm=norm)\n",
    "                ax.scatter(cutout.wcs.world_to_pixel(coord)[0], cutout.wcs.world_to_pixel(coord)[1],\n",
    "                        s=400, edgecolor='yellow', facecolor='none', marker='o', lw=1, alpha=0.7)\n",
    "                # WCSAxes niceties\n",
    "                ax.set_xlabel(\"RA\")\n",
    "                ax.set_ylabel(\"Dec\")\n",
    "                ax.coords.grid(True, alpha=0.3, linestyle=\"--\")\n",
    "                plt.tight_layout()\n",
    "                fig_path = f\"data/comets/figs/ztf/{comet_name.replace('/', '_')}_ztf_{obs_time.iso}_{filter_band}.png\"\n",
    "                plt.savefig(fig_path)\n",
    "                print(f'Saved figure to {fig_path}')\n",
    "                plt.show()\n",
    "        finally:\n",
    "            try:\n",
    "                hdul.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "        # break\n",
    "# # hdul.close()\n",
    "    # break\n",
    "# df_ztf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_name = \"C/2009 F2\"\n",
    "t = Time(58204.5145255113, format='mjd', scale='utc')\n",
    "# t.iso\n",
    "obj = Horizons(id=comet_name, location='I41', epochs=t.mjd)\n",
    "eph = obj.ephemerides()\n",
    "eph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
