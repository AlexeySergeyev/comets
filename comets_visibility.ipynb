{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy\n",
    "from astropy.table import Table, join, vstack\n",
    "from astropy.time import Time\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "\n",
    "from astroquery.jplhorizons import Horizons\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "import time\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "saveplots = False # set to save some of the plots to png files\n",
    "import pandas as pd\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cadc_ssos_query(object_name, search=\"bynameall\", \n",
    "                    # epoch1=50000, epoch2=57079,\n",
    "                    xyres=\"no\", \n",
    "                    # telinst=\"Pan-STARRS1\", \n",
    "                    lang=\"en\", format=\"tsv\",\n",
    "                    url=\"https://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/cadcbin/ssos/ssosclf.pl\"):\n",
    "    \"\"\"Use CADC moving object query to find PS1 observations by target name\n",
    "    \n",
    "    The epoch parameters give the range in MJD for the PS1 observations.\n",
    "    The only parameter that might be usefully modified is the search.  \n",
    "    E.g., use search=\"bynameHorizons\" to search using the JPL Horizons emphemeris rather\n",
    "    than the ephemeris cached at CADC.  That might be useful if the CADC cache has become\n",
    "    out-of-date.\n",
    "    \n",
    "    This return an astropy table with the observations.\n",
    "    \"\"\"\n",
    "    t0 = Time('1990-01-01 00:00:00', format='iso', scale='utc')\n",
    "    t1 = Time.now()\n",
    "\n",
    "    print(f\"Querying CADC SSOS for object '{object_name}' between {t0.iso} and {t1.iso}\")\n",
    "    params = dict(\n",
    "        lang=lang,\n",
    "        object=object_name,\n",
    "        search=search,\n",
    "        epoch1=t0.mjd,\n",
    "        epoch2=t1.mjd,\n",
    "        format=format\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=60)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"HTTP request failed: {e}\")\n",
    "        # Return an empty table with expected columns so downstream code doesn't crash\n",
    "        cols = ['Image', 'MJD', 'Filter', 'Exptime', 'Object_RA', 'Object_Dec',\n",
    "                'Image_target', 'Telescope/Instrument', 'MetaData', 'Datalink']\n",
    "        return Table.from_pandas(pd.DataFrame(columns=cols))\n",
    "\n",
    "    print(r.url)\n",
    "\n",
    "    text = r.text\n",
    "    first_line = text.strip().split('\\n', 1)[0]\n",
    "\n",
    "    # Detect common error responses from CADC / Horizons and HTML error pages\n",
    "    if (first_line.lower().startswith(\"there was an error\") or\n",
    "        \"error\" in first_line.lower() or\n",
    "        first_line.strip().startswith(\"<!DOCTYPE\") or\n",
    "        first_line.strip().startswith(\"<html\")):\n",
    "        # Clean up message for printing\n",
    "        msg = first_line.replace('<br/>', '').strip()\n",
    "        print(f\"CADC/SSOS returned an error: {msg}\")\n",
    "        # Try a simple fallback: switch to CADC cached ephemerides if not already using it\n",
    "        if search != \"bynameCADC\":\n",
    "            print(\"Retrying with search='bynameCADC'...\")\n",
    "            return cadc_ssos_query(object_name, search=\"bynameCADC\", xyres=xyres, lang=lang, format=format, url=url)\n",
    "        # Otherwise return an empty table with expected columns\n",
    "        cols = ['Image', 'MJD', 'Filter', 'Exptime', 'Object_RA', 'Object_Dec',\n",
    "                'Image_target', 'Telescope/Instrument', 'MetaData', 'Datalink']\n",
    "        return Table.from_pandas(pd.DataFrame(columns=cols))\n",
    "\n",
    "    # Parse TSV using pandas to avoid astropy fast C-reader converter limitations\n",
    "    try:\n",
    "        df = pd.read_csv(StringIO(text), sep='\\t', engine='python', on_bad_lines='skip')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse CADC TSV: {e}\")\n",
    "        # Return empty table with expected columns to keep pipeline running\n",
    "        cols = ['Image', 'MJD', 'Filter', 'Exptime', 'Object_RA', 'Object_Dec',\n",
    "                'Image_target', 'Telescope/Instrument', 'MetaData', 'Datalink']\n",
    "        return Table.from_pandas(pd.DataFrame(columns=cols))\n",
    "\n",
    "    # Ensure expected columns exist even if CADC response changes\n",
    "    expected_cols = ['Image', 'MJD', 'Filter', 'Exptime', 'Object_RA', 'Object_Dec',\n",
    "                     'Image_target', 'Telescope/Instrument', 'MetaData', 'Datalink']\n",
    "    for col in expected_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "\n",
    "    # Ensure string type for Image_target if present\n",
    "    if 'Image_target' in df.columns:\n",
    "        df['Image_target'] = df['Image_target'].astype(str)\n",
    "\n",
    "    return Table.from_pandas(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple ephemerides query\n",
    "def ephemcc(ident, ep, nbd=None, step=None, observer='645', rplane='1', tcoor=5):\n",
    "    '''Gets asteroid ephemerides from IMCCE Miriade for a suite of JD for a single SSO\n",
    "    Original function by M. Mahlke\n",
    "\n",
    "    :ident: int, float, str - asteroid identifier\n",
    "    :ep: float, str, list - Epoch of computation\n",
    "    :observer: str - IAU Obs code - default to geocenter: https://minorplanetcenter.net//iau/lists/ObsCodesF.html\n",
    "    :returns: pd.DataFrame - Input dataframe with ephemerides columns appended\n",
    "              False - If query failed somehow\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # ------\n",
    "    # Miriade URL \n",
    "    url = 'https://ssp.imcce.fr/webservices/miriade/api/ephemcc.php'\n",
    "    \n",
    "    #if rplane=='2':\n",
    "    #    tcoor='1'\n",
    "        \n",
    "    # Query parameters\n",
    "    params = {\n",
    "        '-name': f'c:{ident}',\n",
    "        '-mime': 'json',\n",
    "        '-rplane': rplane,\n",
    "        '-tcoor': tcoor,\n",
    "        '-output': '--jd',\n",
    "        '-observer': observer, \n",
    "        '-tscale': 'UTC',\n",
    "        '-type': 'Asteroid'\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Single epoch of computation\n",
    "    if type(ep)!=list:\n",
    "        # Set parameters\n",
    "        params['-ep'] = ep\n",
    "        if nbd!=None: \n",
    "            params['-nbd'] = nbd\n",
    "        if step!=None: \n",
    "            params['-step'] = step\n",
    "\n",
    "        # Execute query\n",
    "        try:\n",
    "            r = requests.post(url, params=params, timeout=80)\n",
    "        except requests.exceptions.ReadTimeout:\n",
    "            return False\n",
    "\n",
    "\n",
    "    # Multiple epochs of computation\n",
    "    else:\n",
    "        # Epochs of computation\n",
    "        files = {'epochs': ('epochs', '\\n'.join(['%.6f' % epoch\n",
    "                                                 for epoch in ep]))}\n",
    "\n",
    "        # Execute query\n",
    "        try:\n",
    "            r = requests.post(url, params=params, files=files, timeout=120)\n",
    "            print(r.url)\n",
    "        except requests.exceptions.ReadTimeout:\n",
    "            return False\n",
    "\n",
    "    j = r.json()\n",
    "\n",
    "    # Read JSON response\n",
    "    try:\n",
    "        ephem = pd.DataFrame.from_dict(j['data'])\n",
    "    except KeyError:\n",
    "        return False\n",
    "\n",
    "    return ephem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decam_cleaner(df: pd.DataFrame)-> pd.DataFrame:\n",
    "    \"\"\"Clean up DECam observation table from CADC SSOS query\n",
    "\n",
    "    This function removes duplicate entries and filters out non-DECam observations.\n",
    "    \"\"\"\n",
    "\n",
    "    def select_decam_images(group):\n",
    "        # Select only calibrated images containing '_ooi'\n",
    "        cond = group['Image'].str.contains('_ooi') | group['Image'].str.contains('_opi')\n",
    "        group_filtered = group[cond]\n",
    "        # If both _opi and _ooi exist, prefer _opi\n",
    "        if group_filtered['Image'].str.contains('_opi').any():\n",
    "            group_filtered = group_filtered[group_filtered['Image'].str.contains('_opi')]\n",
    "        if len(group_filtered) > 1:\n",
    "            if group_filtered['Image'].str.contains('_v4').any():\n",
    "                return group_filtered[group_filtered['Image'].str.contains('_v4')]\n",
    "            elif group_filtered['Image'].str.contains('_v3').any():\n",
    "                return group_filtered[group_filtered['Image'].str.contains('_v3')]\n",
    "            elif group_filtered['Image'].str.contains('_v2').any():\n",
    "                return group_filtered[group_filtered['Image'].str.contains('_v2')]\n",
    "            elif group_filtered['Image'].str.contains('_v1').any():\n",
    "                return group_filtered[group_filtered['Image'].str.contains('_v1')]\n",
    "            else:\n",
    "                return group_filtered.iloc[[0]]\n",
    "        else:\n",
    "            return group_filtered\n",
    "\n",
    "    # Filter to only include DECam observations (make a copy to avoid SettingWithCopyWarning)\n",
    "    df_decam = df[df['Telescope/Instrument'].str.contains('DECam', na=False)].copy()\n",
    "\n",
    "    if df_decam.empty:\n",
    "        return df\n",
    "\n",
    "    # Remove decam images from the original dataframe\n",
    "    df = df.drop(df_decam.index)\n",
    "\n",
    "    # Further filter to only images starting with 'c4d_'\n",
    "    cond = df_decam['Image'].str.startswith('c4d_')\n",
    "    df_decam = df_decam[cond]\n",
    "\n",
    "    # Recompute grouping key (assign via .loc to avoid SettingWithCopyWarning)\n",
    "    df_decam.loc[:, 'date'] = df_decam['Image'].apply(lambda x: \"_\".join(x.split('_')[:3]))\n",
    "    gr = df_decam.groupby('date')\n",
    "\n",
    "    if gr.ngroups == 0:\n",
    "        return df_decam\n",
    "\n",
    "    # Check pandas version to use correct apply syntax\n",
    "    if hasattr(pd, '__version__') and int(pd.__version__.split('.')[0]) >= 2:\n",
    "        df_selected = gr.apply(select_decam_images, include_groups=False) # type: ignore\n",
    "    else:\n",
    "        df_selected = gr.apply(select_decam_images)\n",
    "\n",
    "    # display(df_decam)\n",
    "    # insert back decam images into the original dataframe\n",
    "    df = pd.concat([df, df_selected], ignore_index=True)\n",
    "    \n",
    "    del df_selected, df_decam\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telescopes visibility from Telescope limits\n",
    "\n",
    "- This should be read for both 1. and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limits = pd.read_csv(\"data/Survey-Filter-LimitingMagnitude-SaturationMagnitude-TypicalExposureTime.csv\")\n",
    "df_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. List of the comets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init = pd.read_csv('data/List of comets.csv')\n",
    "df_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read tables from CADC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for i, row in df_init.iterrows():\n",
    "    print(f\"{i}: {row['Comet name']}\")\n",
    "    source = df_init.loc[i, 'Comet name']\n",
    "    name = \" \".join(source.split())\n",
    "\n",
    "    cadc_tab = cadc_ssos_query(name)\n",
    "    print(f\"Returned table has {len(cadc_tab)} rows\")\n",
    "    df_comet = cadc_tab.to_pandas()\n",
    "    df_comet.to_csv(f\"data/cadc/{name.replace('/', '_')}_cadc.csv\", index=False)\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Miriade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_limit = 500\n",
    "for i, row in df_init[1:].iterrows():\n",
    "    print(f\"{i}: {row['Comet name']}\")\n",
    "    source = df_init.loc[i, 'Comet name']\n",
    "    name = \" \".join(source.split())\n",
    "    filename = f\"data/cadc/{name.replace('/', '_')}_cadc.csv\"\n",
    "    df_obs = pd.read_csv(filename)\n",
    "    \n",
    "    chunks = len(df_obs) // rows_limit + 1\n",
    "    print(f\"  Read {len(df_obs)} observations from {filename} in {chunks} chunks\")\n",
    "\n",
    "    df_comet = None\n",
    "    for chunk in range(chunks):\n",
    "        start = chunk * rows_limit\n",
    "        end = min((chunk + 1) * rows_limit, len(df_obs))\n",
    "        jds = (df_obs['MJD'].values[start:end] + 2400000.5).tolist()\n",
    "        \n",
    "        ephem = ephemcc(name, jds, observer='500', rplane='1', tcoor=5)\n",
    "        if ephem is False:\n",
    "            print(f\"  Miriade query failed for {name}\")\n",
    "            continue\n",
    "        \n",
    "        if df_comet is None:\n",
    "            df_comet = ephem\n",
    "        else:\n",
    "            df_comet = pd.concat([df_comet, ephem], ignore_index=True)\n",
    "\n",
    "    if df_comet is not None:\n",
    "        print(f\"Got {len(df_comet)} ephemeris rows from Miriade\")\n",
    "        df_comet.to_csv(f\"data/miriade/{name.replace('/', '_')}_miriade.csv\", index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = 0\n",
    "for i, row in df_init[0:].iterrows():\n",
    "    name = \" \".join(row['Comet name'].split())\n",
    "    cadc_filename = f\"data/cadc/{name.replace('/', '_')}_cadc.csv\"\n",
    "    miriade_filename = f\"data/miriade/{name.replace('/', '_')}_miriade.csv\"\n",
    "    try:\n",
    "        df_cadc = pd.read_csv(cadc_filename)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{name}: CADC file not found\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df_miriade = pd.read_csv(miriade_filename)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{name}: Miriade file not found\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.merge(df_cadc, df_miriade, left_index=True, right_index=True, suffixes=('_cadc', '_miriade'))\n",
    "    print(f\"{name}: merged {len(df)} rows\")\n",
    "    \n",
    "    cond = (df['VMag'] < 18) & (df[\"Telescope/Instrument\"] == \"NEOSSat\")\n",
    "    df_visible = df[cond]\n",
    "    counts += len(df_visible)\n",
    "    # break\n",
    "print(f\"Total visible observations: {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visible.value_counts('Telescope/Instrument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in df_init[5:].iterrows():\n",
    "#     name = \" \".join(row['Comet name'].split())\n",
    "#     cadc_filename = f\"data/cadc/{name.replace('/', '_')}_cadc.csv\"\n",
    "#     miriade_filename = f\"data/miriade/{name.replace('/', '_')}_miriade.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. New list of the comets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = \"C/2004 D1, C/2005 R4, C/2005 T3, C/2006 L1, C/2006 Q1, C/2007 N3, C/2007 R1, C/2008 FK75, C/2009 F2, C/2009 S3, C/2009 U5, C/2010 G2, C/2012 A1, C/2016 R2, C/2023 H5\"\n",
    "df_init = pd.DataFrame({\"Comet\": l2.split(\", \")})\n",
    "df_init.to_csv(\"data/comets_list2.csv\", index=False)\n",
    "df_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get possible dates of observation from CADC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for i, row in df_init.iterrows():\n",
    "    print(f\"{i}: {row['Comet']}\")\n",
    "    source = df_init.loc[i, 'Comet']\n",
    "    name = \" \".join(source.split())\n",
    "    cadc_filename = f\"data/cadc2/{name.replace('/', '_')}_cadc.csv\"\n",
    "\n",
    "    if os.path.exists(cadc_filename):\n",
    "        print(f\"  File {cadc_filename} exists, skipping\")\n",
    "        continue\n",
    "\n",
    "    cadc_tab = cadc_ssos_query(name)\n",
    "    \n",
    "    print(f\"Returned table has {len(cadc_tab)} rows\")\n",
    "    df_comet = cadc_tab.to_pandas()\n",
    "    # display(df_comet)\n",
    "    \n",
    "    # clean DECam entries\n",
    "    # df_comet_cleaned = decam_cleaner(df_comet)\n",
    "    # print(f\"After DECam cleaning, {len(df_comet_cleaned)} rows remain\")\n",
    "    df_comet.to_csv(cadc_filename, index=False)\n",
    "    # if i == 3:\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ephemerides from Miriade for the selected dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_limit = 2000\n",
    "for i, row in df_init[1:].iterrows():\n",
    "    print(f\"{i}: {row['Comet']}\")\n",
    "    source = df_init.loc[i, 'Comet']\n",
    "    name = \" \".join(source.split())\n",
    "    cadc_filename = f\"data/cadc2/{name.replace('/', '_')}_cadc.csv\"\n",
    "    miriade_filename = f\"data/miriade2/{name.replace('/', '_')}_miriade.csv\"\n",
    "    if os.path.exists(miriade_filename):\n",
    "        print(f\"  File {miriade_filename} exists, skipping\")\n",
    "        continue\n",
    "\n",
    "    df_obs = pd.read_csv(cadc_filename)\n",
    "    chunks = len(df_obs) // rows_limit + 1\n",
    "    print(f\"  Read {len(df_obs)} observations from {cadc_filename} in {chunks} chunks\")\n",
    "\n",
    "    df_comet = None\n",
    "    for chunk in range(chunks):\n",
    "        start = chunk * rows_limit\n",
    "        end = min((chunk + 1) * rows_limit, len(df_obs))\n",
    "        jds = (df_obs['MJD'].values[start:end] + 2400000.5).tolist()\n",
    "        \n",
    "        ephem = ephemcc(name, jds, observer='500', rplane='1', tcoor=5)\n",
    "        if ephem is False:\n",
    "            print(f\"Miriade query failed for {name}\")\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "        \n",
    "        if df_comet is None:\n",
    "            df_comet = ephem\n",
    "        else:\n",
    "            df_comet = pd.concat([df_comet, ephem], ignore_index=True)\n",
    "\n",
    "    if df_comet is not None:\n",
    "        print(f\"Got {len(df_comet)} ephemeris rows from Miriade\")\n",
    "        df_comet.to_csv(miriade_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ephemerides from JPL Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_init.iterrows():\n",
    "    print(f\"{i}: {row['Comet']}\")\n",
    "    source = df_init.loc[i, 'Comet']\n",
    "    name = \" \".join(source.split())\n",
    "\n",
    "    cadc_filename = f\"data/cadc2/{name.replace('/', '_')}_cadc.csv\"\n",
    "    jplh_filename = f\"data/jpl2/{name.replace('/', '_')}_jplhorizons.csv\"\n",
    "    if not os.path.exists(cadc_filename):\n",
    "        print(f\"  CADC file {cadc_filename} not found, skipping\")\n",
    "        continue\n",
    "    \n",
    "    if os.path.exists(jplh_filename):\n",
    "        print(f\"  JPL Horizons file {jplh_filename} already exists, skipping\")\n",
    "        continue\n",
    "    \n",
    "    df_cadc = pd.read_csv(cadc_filename)\n",
    "\n",
    "    emin = Time(df_cadc['MJD'].min(), format='mjd')\n",
    "    emax = Time(df_cadc['MJD'].max(), format='mjd')\n",
    "\n",
    "    print(f\"Have {name} from {emin.isot} to {emax.isot} ({emax.mjd-emin.mjd:.0f} days)\")\n",
    "\n",
    "    # query using 1-day time steps\n",
    "    obj = Horizons(id=name, location='500', \n",
    "                   epochs=dict(start=emin.isot, stop=emax.isot, step='1d'))#, \n",
    "\n",
    "    jpltab = obj.ephemerides(extra_precision=True)\n",
    "    fullname = jpltab['targetname'][0]\n",
    "    print(f\"Got positions from Horizons with {len(jpltab)} rows for {fullname}\")\n",
    "\n",
    "    # save to CSV\n",
    "    jpltab.to_pandas().to_csv(jplh_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results\n",
    "\n",
    "- Output useful (visible) observations as e.g., `./data/visible2/C_2004D1_visible.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = 0\n",
    "\n",
    "# Directory with output data\n",
    "outdir = \"./data/visible2\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "\n",
    "for i, row in df_init[0:].iterrows():\n",
    "    is_cadc = False\n",
    "    is_miriade = False\n",
    "    is_jplh = False\n",
    "    \n",
    "    name = \" \".join(row['Comet'].split())\n",
    "    cadc_filename = f\"data/cadc2/{name.replace('/', '_')}_cadc.csv\"\n",
    "    miriade_filename = f\"data/miriade2/{name.replace('/', '_')}_miriade.csv\"\n",
    "    jplh_filename = f\"data/jpl2/{name.replace('/', '_')}_jplhorizons.csv\"\n",
    "    try:\n",
    "        df_cadc = pd.read_csv(cadc_filename)\n",
    "        is_cadc = True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{name}: CADC file not found\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df_jplh = pd.read_csv(jplh_filename)\n",
    "        is_jplh = True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{name}: JPL Horizons file not found\")\n",
    "        # continue\n",
    "\n",
    "    if is_jplh:\n",
    "        df_merged = pd.merge(df_cadc, df_jplh, left_index=True, right_index=True, suffixes=('_cadc', '_jplh'))\n",
    "    else:\n",
    "        print(f\"{name}: No JPL Horizons data to merge\")\n",
    "        continue\n",
    "        \n",
    "    # print(f\"{name}: merged {len(df_merged)} rows\")\n",
    "    # display(df_merged[['Telescope/Instrument', 'Filter']].value_counts())\n",
    "\n",
    "    # Keep only needed columns\n",
    "    limits = df_limits[[c for c in ['Telescope/Instrument', 'Filter', 'Limiting', 'Saturation'] if c in df_limits.columns]].dropna(subset=['Telescope/Instrument'])\n",
    "\n",
    "    # Keep only observations whose Telescope/Instrument exists in the limits\n",
    "    valid_instr = set(limits['Telescope/Instrument'].unique())\n",
    "    df_merged = df_merged[df_merged['Telescope/Instrument'].isin(valid_instr)].copy()\n",
    "\n",
    "    # Attach limits to each observation; inner keeps only matched (Instrument, Filter)\n",
    "    df_with_limits = df_merged.merge(limits, on=['Telescope/Instrument', 'Filter'], how='inner')\n",
    "\n",
    "    # Condition: not saturated (Tmag >= Saturation) and not too faint (Tmag <= Limiting)\n",
    "    cond = (df_with_limits['Tmag'] >= df_with_limits['Saturation']) & (df_with_limits['Tmag'] <= df_with_limits['Limiting'])\n",
    "\n",
    "    df_visible = df_with_limits[cond]\n",
    "\n",
    "    # Save visible observations \n",
    "    out = f\"{name.replace('/', '_').replace(' ', '')}_visible.csv\"\n",
    "    out = os.path.join(outdir, out)\n",
    "    df_visible.to_csv(out, sep=\",\")\n",
    "\n",
    "    if len(df_visible) != 0:\n",
    "        print(f\"{i} - {name}: {len(df_visible)} visible observations\")\n",
    "        display(df_visible[['Telescope/Instrument', 'Filter']].value_counts())\n",
    "        counts += len(df_visible)\n",
    "    else:\n",
    "        print(f\"{name}: No visible observations\")\n",
    "\n",
    "    # if i == 2:\n",
    "    #     break\n",
    "print(f\"Total visible observations: {counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name= \"C/2023 H5\"\n",
    "# name = \"C/2005 R4\"\n",
    "name = df_init.loc[13, 'Comet']\n",
    "print(name)\n",
    "cadc_filename = f\"data/cadc2/{name.replace('/', '_')}_cadc.csv\"\n",
    "miriade_filename = f\"data/miriade2/{name.replace('/', '_')}_miriade.csv\"\n",
    "try:\n",
    "    df_cadc = pd.read_csv(cadc_filename)\n",
    "except FileNotFoundError:\n",
    "    print(f\"{name}: CADC file not found\")\n",
    "    df_cadc = pd.DataFrame()\n",
    "try:    df_miriade = pd.read_csv(miriade_filename)\n",
    "except FileNotFoundError:\n",
    "    print(f\"{name}: Miriade file not found\")\n",
    "    df_miriade = pd.DataFrame()\n",
    "df = pd.merge(df_cadc, df_miriade, left_index=True, right_index=True, suffixes=('_cadc', '_miriade'))\n",
    "print(f\"{name}: merged {len(df)} rows\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# PS1 epoch range with epoch edges set to round days\n",
    "jplh_filename = f\"data/jpl2/{name.replace('/', '_')}_jplhorizons.csv\"\n",
    "df_jplh = pd.read_csv(jplh_filename)\n",
    "fullname = df_jplh['targetname'][0]\n",
    "print(f\"Got positions from Horizons with {len(df_jplh)} rows for {fullname}\")\n",
    "df_jplh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undo RA-wrapping from 0-360 degrees\n",
    "# add or subtract multiples of 360 to create a smooth path\n",
    "njumps = 0\n",
    "ra_deg = df_jplh['RA'].to_numpy(copy=True)\n",
    "\n",
    "# Count wrap jumps in the original series (optional)\n",
    "d = np.diff(ra_deg)\n",
    "njumps = int((d > 180).sum() + (d < -180).sum())\n",
    "\n",
    "# Unwrap using numpy (threshold = 180 deg)\n",
    "ratab = np.rad2deg(np.unwrap(np.deg2rad(ra_deg), discont=np.deg2rad(180)))\n",
    "\n",
    "# Shift to non-negative range\n",
    "if ratab.min() < 0:\n",
    "    ratab += 360.0 * np.ceil(-ratab.min() / 360.0)\n",
    "\n",
    "# plt.rcParams.update({\"font.size\":14})\n",
    "plt.figure(1, (12, 6))\n",
    "plt.plot(ratab, df_jplh['DEC'])\n",
    "\n",
    "# plot every 30 days as a dot to see movement\n",
    "mstep = int(30 / (df_jplh['datetime_jd'][1] - df_jplh['datetime_jd'][0]) + 0.5)\n",
    "plt.plot(ratab[::mstep], df_jplh['DEC'][::mstep], '.', color=\"tab:blue\", label=\"Monthly positions\")\n",
    "\n",
    "# show positions at the times of observations\n",
    "jpl_mjd = Time(df_jplh['datetime_jd'], format='jd').mjd\n",
    "ra_interp = np.interp(df['MJD'], jpl_mjd, ratab)\n",
    "dec_interp = np.interp(df['MJD'], jpl_mjd, df_jplh['DEC'])\n",
    "\n",
    "df_instr = df[['Telescope/Instrument', 'Filter']].value_counts()\n",
    "df_instr = df_instr[df_instr > 10]\n",
    "for (instr, filt), count in df_instr.items():\n",
    "    cond = (df['Telescope/Instrument'] == instr) & (df['Filter'] == filt)\n",
    "    plt.plot(ra_interp[cond], dec_interp[cond], '*', markersize=10,\n",
    "             label=f\"{instr} {filt} ({count})\")\n",
    "\n",
    "plt.xlabel(\"Unwrapped RA [deg]\")\n",
    "plt.ylabel(\"Dec [deg]\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title(f\"{fullname} from {emin.isot[:10]} to {emax.isot[:10]}\")\n",
    "plt.tight_layout()\n",
    "plt.grid(linestyle='--', alpha=0.5)\n",
    "# if saveplots:\n",
    "#     plt.savefig(\"sky_path.png\", facecolor=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_interp = np.interp(df_cadc['MJD'], jpl_mjd, df_jplh['alpha']) \n",
    "# Nmag\n",
    "nmag_interp = np.interp(df_cadc['MJD'], jpl_mjd, df_jplh['Nmag'])\n",
    "# distance from the Sun\n",
    "r_interp = np.interp(df_cadc['MJD'], jpl_mjd, df_jplh['r'])\n",
    "\n",
    "# plt.rcParams.update({\"font.size\":14})\n",
    "plt.figure(1,(12,6))\n",
    "# plt.plot(ratab, jpltab['DEC'])\n",
    "\n",
    "df_instr = df_cadc[['Telescope/Instrument', 'Filter']].value_counts()\n",
    "df_instr = df_instr[df_instr > 1]\n",
    "for (instr, filt), count in df_instr.items():\n",
    "    cond = (df_cadc['Telescope/Instrument'] == instr) & (df_cadc['Filter'] == filt)\n",
    "    plt.plot(\n",
    "        # phase_interp[cond], \n",
    "        r_interp[cond],\n",
    "         nmag_interp[cond], \n",
    "        '*', markersize=10,\n",
    "        label=f\"{instr} {filt} ({count})\")\n",
    "# plt.plot(ra_interp, dec_interp, 'o', color=\"tab:orange\", label=f\"{len(df)} observations\")\n",
    "\n",
    "plt.xlabel(\"The distance from the Sun [au]\")\n",
    "plt.ylabel(\"Nmag [mag]\")\n",
    "# plt.xlim(left=0)\n",
    "# limit legend by 30 entries\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "if len(handles) > 30:\n",
    "    handles = handles[:30]\n",
    "    labels = labels[:30]\n",
    "    plt.gca().legend(handles, labels, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "\n",
    "plt.title(f\"{fullname} from {emin.isot[:10]} to {emax.isot[:10]}\")\n",
    "plt.tight_layout()\n",
    "plt.grid(linestyle='--', alpha=0.5)\n",
    "# if saveplots:\n",
    "#     plt.savefig(\"sky_path.png\", facecolor=\"white\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
